{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da50feb",
   "metadata": {},
   "source": [
    "<div id=\"container\" style=\"position:relative;\">\n",
    "<div style=\"float:left\"><h1> Mahyar Sabouniaghdam</h1></div>\n",
    "<div style=\"position:relative; float:right\"><img style=\"height:65px\" src =\"https://drive.google.com/uc?export=view&id=1EnB0x-fdqMp6I5iMoEBBEuxB_s7AmE2k\" />\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a5f40",
   "metadata": {},
   "source": [
    "#### Gmail: saboonimahyar@gmail.com\n",
    "\n",
    "#### LinkedIn Profile: https://www.linkedin.com/in/mahyar-sabouniaghdam/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee0875",
   "metadata": {},
   "source": [
    "# BrainStation Capstone Project : Stack Overflow Questions Quality Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf30f9",
   "metadata": {
    "id": "5BQ7jdWyVTzo"
   },
   "source": [
    "## Table of Contents:\n",
    "\n",
    "* [Artificial Neural Networks (ANNs)](#1)\n",
    "* [Multi Class Neural Networks](#2)\n",
    "* [Random Forest ](#3)\n",
    "* [XGBoost ](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7b46e",
   "metadata": {},
   "source": [
    "Note: This notebook was run in the deeplearning environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc6589",
   "metadata": {},
   "source": [
    "This notebook in a supplemantry notebook which we will run some deeplearning and rerun my advanced models again:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b55bf4",
   "metadata": {},
   "source": [
    "- Let's import some packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fac4a00",
   "metadata": {
    "id": "7ZjuapQJVTzp"
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0a373d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, \n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    plot_confusion_matrix, plot_roc_curve\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa7213",
   "metadata": {},
   "source": [
    "Let's read our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47feef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_remainder_vect_tfidf.csv')\n",
    "X_test = pd.read_csv('X_test_vect_tfidf.csv')\n",
    "y_train = pd.read_csv('y_remainder.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd3b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataframe is: (22498, 2018).\n",
      "The shape of the X_test dataframe is: (7500, 2018).\n",
      "\n",
      "The shape of the y_train dataframe is: (22498, 1).\n",
      "The shape of the y_test dataframe is: (7500, 1).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check dataframes shapes\n",
    "\n",
    "print(f\"The shape of the X_train dataframe is: {X_train.shape}.\")\n",
    "print(f\"The shape of the X_test dataframe is: {X_test.shape}.\\n\")\n",
    "print(f\"The shape of the y_train dataframe is: {y_train.shape}.\")\n",
    "print(f\"The shape of the y_test dataframe is: {y_test.shape}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebebba",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3b5f5",
   "metadata": {},
   "source": [
    "Now I am going to apply MinMaxScaler to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c039237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# instantiate the model\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit the model\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "# transform\n",
    "X_train_scaled= scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a3621",
   "metadata": {},
   "source": [
    "- Now let's create some functions for evaluation of ANN and printing the score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9f5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(true, pred, train=True):\n",
    "    if train:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "        \n",
    "def plot_learning_evolution(r):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(r.history['loss'], label='Loss')\n",
    "    plt.plot(r.history['val_loss'], label='val_Loss')\n",
    "    plt.title('Loss evolution during trainig')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(r.history['AUC'], label='AUC')\n",
    "    plt.plot(r.history['val_AUC'], label='val_AUC')\n",
    "    plt.title('AUC score evolution during trainig')\n",
    "    plt.legend();\n",
    "\n",
    "def nn_model(num_columns, num_labels, hidden_units, dropout_rates, learning_rate):\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns, ))\n",
    "    x = BatchNormalization()(inp)\n",
    "    x = Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = Dense(hidden_units[i], activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout_rates[i + 1])(x)\n",
    "    x = Dense(num_labels, activation='sigmoid')(x)\n",
    "  \n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=[AUC(name='AUC')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ff1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(true, pred, train=True):\n",
    "    if train:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fe12d",
   "metadata": {},
   "source": [
    "## ANN Model <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9d975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.5935 - AUC: 0.7526 - val_loss: 0.5535 - val_AUC: 0.8069\n",
      "Epoch 2/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.4293 - AUC: 0.8803 - val_loss: 0.5791 - val_AUC: 0.8105\n",
      "Epoch 3/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.3686 - AUC: 0.9137 - val_loss: 0.6338 - val_AUC: 0.8085\n",
      "Epoch 4/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.3202 - AUC: 0.9359 - val_loss: 0.8116 - val_AUC: 0.7916\n",
      "Epoch 5/20\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 0.2811 - AUC: 0.9509 - val_loss: 0.9192 - val_AUC: 0.7804\n",
      "Epoch 6/20\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 0.2457 - AUC: 0.9626 - val_loss: 1.0817 - val_AUC: 0.7732\n",
      "Epoch 7/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.2128 - AUC: 0.9720 - val_loss: 1.1727 - val_AUC: 0.7631\n",
      "Epoch 8/20\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 0.2059 - AUC: 0.9736 - val_loss: 1.2488 - val_AUC: 0.7571\n",
      "Epoch 9/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.1785 - AUC: 0.9802 - val_loss: 1.3612 - val_AUC: 0.7614\n",
      "Epoch 10/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.1652 - AUC: 0.9828 - val_loss: 1.4985 - val_AUC: 0.7638\n",
      "Epoch 11/20\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 0.1607 - AUC: 0.9839 - val_loss: 1.4321 - val_AUC: 0.7659\n",
      "Epoch 12/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.1519 - AUC: 0.9854 - val_loss: 1.4506 - val_AUC: 0.7543\n",
      "Epoch 13/20\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 0.1404 - AUC: 0.9875 - val_loss: 1.4911 - val_AUC: 0.7476\n",
      "Epoch 14/20\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1355 - AUC: 0.9882 - val_loss: 1.5944 - val_AUC: 0.7501\n",
      "Epoch 15/20\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.1288 - AUC: 0.9894 - val_loss: 1.6686 - val_AUC: 0.7467\n",
      "Epoch 16/20\n",
      "704/704 [==============================] - 5s 6ms/step - loss: 0.1151 - AUC: 0.9915 - val_loss: 1.6502 - val_AUC: 0.7564\n",
      "Epoch 17/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.1214 - AUC: 0.9905 - val_loss: 1.7329 - val_AUC: 0.7533\n",
      "Epoch 18/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.1139 - AUC: 0.9915 - val_loss: 1.6903 - val_AUC: 0.7595\n",
      "Epoch 19/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.1052 - AUC: 0.9928 - val_loss: 1.7030 - val_AUC: 0.7618\n",
      "Epoch 20/20\n",
      "704/704 [==============================] - 4s 6ms/step - loss: 0.1032 - AUC: 0.9926 - val_loss: 1.6521 - val_AUC: 0.7589\n"
     ]
    }
   ],
   "source": [
    "num_columns = X_train_scaled.shape[1]\n",
    "num_labels = 1\n",
    "hidden_units = [150, 150, 150]\n",
    "dropout_rates = [0.1, 0, 0.1, 0]\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "model = nn_model(\n",
    "    num_columns=num_columns, \n",
    "    num_labels=num_labels,\n",
    "    hidden_units=hidden_units,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "r = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c630d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.44%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.648215     0.756625    0.7044     0.702420      0.709098\n",
      "recall        0.712287     0.698243    0.7044     0.705265      0.704400\n",
      "f1-score      0.678742     0.726263    0.7044     0.702502      0.705430\n",
      "support    3288.000000  4212.000000    0.7044  7500.000000   7500.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[2342  946]\n",
      " [1271 2941]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test_scaled)\n",
    "evaluate_nn(y_test, y_test_pred.round(), train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d664c84a",
   "metadata": {},
   "source": [
    "- The Test accuracy score for ANN is 70.5% which is lower from our XGBoost model in previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde4223",
   "metadata": {},
   "source": [
    "## Multi Class Neural Networks <a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f55c22",
   "metadata": {},
   "source": [
    "- Let's import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970b2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ce01d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seeds for reproducibility\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# Create a new sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Declare the hidden layers\n",
    "model.add(layers.Dense(40, activation=\"relu\"))\n",
    "model.add(layers.Dense(40, activation=\"relu\"))\n",
    "model.add(layers.Dense(40, activation=\"relu\"))\n",
    "\n",
    "# Declare the output layer\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.Adam(),  \n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # Metric used to evaluate model\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b94c52fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_20 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8929c078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8358\n",
      "Test Accuracy: 0.7936\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data and generate predictions\n",
    "\n",
    "train_accuracy = history.history[\"sparse_categorical_accuracy\"][-1]\n",
    "result = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {result[1]:.4f}\")\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc0f1f",
   "metadata": {},
   "source": [
    "- Here we have 79% Test score which is almost the same as our XGBoost Model in previos notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a2adb",
   "metadata": {},
   "source": [
    "I will rerun these 2 models again here for comparing with NNs models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088ff08",
   "metadata": {},
   "source": [
    "## Random Forest <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c43f2",
   "metadata": {},
   "source": [
    "- Let's run the Random Forest model here again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d13e9a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahya\\AppData\\Local\\Temp\\ipykernel_5464\\892756727.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 81.99%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0             1  accuracy     macro avg  weighted avg\n",
      "precision     0.812752      0.825046  0.819895      0.818899      0.819610\n",
      "recall        0.770105      0.859363  0.819895      0.814734      0.819895\n",
      "f1-score      0.790854      0.841855  0.819895      0.816354      0.819303\n",
      "support    9948.000000  12550.000000  0.819895  22498.000000  22498.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 7661  2287]\n",
      " [ 1765 10785]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 71.60%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.688477     0.735095     0.716     0.711786      0.714657\n",
      "recall        0.643248     0.772792     0.716     0.708020      0.716000\n",
      "f1-score      0.665094     0.753472     0.716     0.709283      0.714727\n",
      "support    3288.000000  4212.000000     0.716  7500.000000   7500.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[2115 1173]\n",
      " [ 957 3255]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train_scaled)\n",
    "y_test_pred = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "print_score(y_train, y_train_pred, train=True)\n",
    "print_score(y_test, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad762b",
   "metadata": {},
   "source": [
    "- The Test accuracy score for Random Forest Classifier is 71.6% which is lower from our XGBoost model in previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e58316",
   "metadata": {},
   "source": [
    "## XGBoost  <a id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af954f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahya\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 79.43%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.770375     0.812310  0.794267     0.791342      0.793926\n",
      "recall        0.756083     0.824074  0.794267     0.790078      0.794267\n",
      "f1-score      0.763162     0.818150  0.794267     0.790656      0.794043\n",
      "support    3288.000000  4212.000000  0.794267  7500.000000   7500.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[2486  802]\n",
      " [ 741 3471]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_test_pred = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "print_score(y_test, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25dd8c",
   "metadata": {},
   "source": [
    "- As we can see here the Test Accuracy score for XGBoost model is 79.43% and it is better han Multi Class NNs model 79.36%. The score is almost the same as XGBoost model in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b407b7",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe441a1c",
   "metadata": {},
   "source": [
    "- It is ture that my NNs models have lower test scores than my XGBoost model in this notebook. NNs models are more complex and I tried and wanted to run some other NNs models but because of computational limits I couldnot. So, my final model would be XGBoost and I will continue with the one I evaluated on previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f716d",
   "metadata": {},
   "source": [
    "- Now we can go back to the previous notebook for final insights, final model and next steps part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214422a9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cadca5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888e6ab",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4409f1d1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e1133",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
